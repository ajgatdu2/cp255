{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling and simulation\n",
    "\n",
    "This demo focuses on approaches from statistics and machine learning that you can easily take advantage of without learning any new math. Most of the methodologies covered in lecture are pretty accessible too, but it's hard to demo everything! Here are some additional resources:\n",
    "\n",
    "- Online textbook for [Data 8](https://www.inferentialthinking.com/) (chapter 9 onward)\n",
    "- Detailed introduction to OLS regression, in a [notebook](https://github.com/waddell/CP255/blob/master/13-regression/statistical-modeling.ipynb) (from CP 255 last year)\n",
    "- Examples from the Statsmodels library: https://www.statsmodels.org/stable/examples/\n",
    "- Examples from the Scikit-Learn library: https://scikit-learn.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Random sampling\n",
    "\n",
    "Often we want to inspect or validate a dataset, but don't have the ability to look in detail at each data point. Random sampling gives us a subset of the data that's more likely to be representative than, for example, looking at the first few lines of the dataset. \n",
    "\n",
    "Intuitively, this makes sense: Usually the top of the dataset includes observations that are all from the same place, or all from the same point in time. And statistics [tells us](https://en.wikipedia.org/wiki/Sampling_(statistics)) that random samples are even more powerful than they seem. A random sample of several dozen data points will give you a good sense of the characteristics of the full dataset, regardless of how large it is. (If you're interested in rare outcomes, you will need a larger sample. As a rule of thumb, increase the sample size until you get a few dozen of whatever kind of data point you're interested in.)\n",
    "\n",
    "In **Python**, NumPy has dozens of random sampling and random number generating functions:   \n",
    "https://docs.scipy.org/doc/numpy-1.15.0/reference/routines.random.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.random()  # random float between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.randint(low=1, high=100, size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How does this work?\n",
    "\n",
    "When computers generate random numbers, they're really just \"pseudo-random\". The algorithm begins with an unlikely-to-be-repeated \"seed\" (like the current time in microseconds), and applies permutations so that the resulting sequence is effectively arbitrary. Read more [here](https://en.wikipedia.org/wiki/Random_number_generation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random sampling in Pandas\n",
    "\n",
    "Conveniently, Pandas can directly give you a random sample of a DataFrame.\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/version/0.24.2/reference/api/pandas.DataFrame.sample.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Zillow rent index data: https://www.zillow.com/research/data/\n",
    "url = \"http://files.zillowstatic.com/research/public/City/City_Zri_AllHomesPlusMultifamily_Summary.csv\"\n",
    "rents = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rents.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rents.sample(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other applications\n",
    "\n",
    "You can also layer random sampling on top of other statistical procedures, for example to perform **cross-validation**. This is when you divide your data into two chunks, a \"training\" set and a \"testing\" set. Use one set to fit a statistical model, and the other to check how well it performs with data it hasn't seen before, to better mimic real-world applications. Read more [here](https://en.wikipedia.org/wiki/Cross-validation_(statistics)). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Generate a list of 50 random integers between 0 and 100. \n",
    "\n",
    "Plot a histogram of them -- if you have a list from NumPy, you can use `pd.Series(my_list).hist()`.\n",
    "\n",
    "How much does the distribution change when you re-run the code? How much does it change if you increase the size of the sample?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Monte Carlo simulation\n",
    "\n",
    "Computers are really good at generating random numbers, and really good at doing the same thing many times. If you're studying some kind of real-world process that involves randomness (like people's behavioral choices, or the weather, or epidemics), you can write code to simulate the process many, many times, to get a sense of what the aggregate outcomes will look like. This approach is called [Monte Carlo simulation](https://en.wikipedia.org/wiki/Monte_Carlo_method#Applications), and it's usually much easier than doing the same thing analytically. For example, this is often used in travel demand modeling or land use modeling.\n",
    "\n",
    "### Example\n",
    "\n",
    "We are building a 50-unit apartment building. Each unit has a 50% chance of being rented by a student, and a 50% change of being rented by someone else. Students have an 80% chance of owning a bicycle and a 10% chance of owning a car. Non-students have a 60% chance of owning a bicycle and a 75% chance of owning a car. What's the range of car and bicycle parking demand that we're likely to see?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate():\n",
    "    \"\"\"\n",
    "    Simulate the number of bikes and cars owned by residents of the building.\n",
    "    \n",
    "    \"\"\"\n",
    "    bike_count = 0\n",
    "    car_count = 0\n",
    "    \n",
    "    for i in range(50):  # do this once for each resident\n",
    "       \n",
    "        if (np.random.random() < 0.5):  # student\n",
    "\n",
    "            if (np.random.random() < 0.8):\n",
    "                bike_count = bike_count + 1\n",
    "\n",
    "            if (np.random.random() < 0.1):\n",
    "                car_count = car_count + 1\n",
    "\n",
    "        else:\n",
    "\n",
    "            if (np.random.random() < 0.6):\n",
    "                bike_count = bike_count + 1\n",
    "\n",
    "            if (np.random.random() < 0.75):\n",
    "                car_count = car_count + 1\n",
    "\n",
    "    return bike_count, car_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the simulation 500 times and plot the range of outcomes\n",
    "\n",
    "bike_counts = []\n",
    "car_counts = []\n",
    "\n",
    "for i in range(500):\n",
    "    a, b = simulate()\n",
    "    bike_counts.append(a)\n",
    "    car_counts.append(b)\n",
    "\n",
    "pd.Series(bike_counts).hist()\n",
    "pd.Series(car_counts).hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Simulate flipping a coin, and plot a histogram of the results.\n",
    "\n",
    "If you flipped a real coin 100 times, how far from 50 would the number of heads or tails need to be before you got suspicious?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
