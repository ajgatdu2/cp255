{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started with data analysis using Pandas\n",
    "\n",
    "Developed by Sam Maurer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas is a popular Python libary for working with data: https://pandas.pydata.org\n",
    "\n",
    "To use it in this notebook, we'll import it and give it the standard alias \"pd\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Pandas data objects: Series and DataFrames\n",
    "\n",
    "Pandas has two standard structures for working with data: \n",
    "- \"Series\" are like lists\n",
    "- \"DataFrames\" are like tables\n",
    "\n",
    "Pandas data objects include some special metadata, like column names and indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_list = [1.4, 5.98, 12, 0.0]\n",
    "\n",
    "print(x_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(x_list)  # type() is a function that identifies the data type of a variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_series = pd.Series({\"x\": [1.4, 5.98, 12, 0.0]})\n",
    "\n",
    "print(x_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(x_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({\"x\": [1.4, 5.98, 12, 0.0], \"y\": [17, 40, 52, 0]})\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you might expect, each of the columns of a DataFrame is a Series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data['x'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas is part of the same ecosystem as Matplotlib and NumPy. Pandas DataFrames even provide built-in shortcuts to quickly plot data with Matplotlib.\n",
    "\n",
    "This line allows the graphics to display directly in the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.plot.scatter('x', 'y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading and displaying data\n",
    "\n",
    "We're going to look at some U.S. housing cost data from Zillow: https://www.zillow.com/research/data/\n",
    "\n",
    "Pandas can load data directly from a URL. In this case, we'll get the median asking rents for 2-bedroom units:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://files.zillowstatic.com/research/public/Metro/Metro_MedianRentalPrice_2Bedroom.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If that cell ran successfully, the data has been loaded.\n",
    "\n",
    "Alternatively, you can load data \"locally\" -- from a file on the machine where Python is running. In this case, you'd pass to `pd.read_csv()` a **file path** instead of a URL.\n",
    "\n",
    "And now we have a DataFrame!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How much data is there? `len()` is a standard Python function to get the length of things. If we pass it a DataFrame, it tells us the number of rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And there's a DataFrame property called `shape` that tells us a little more:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape  # rows x columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(In case you're curious why there aren't any parentheses at the end of `df.shape`, it's because \"shape\" isn't a function that we're executing, but rather a metadata property of the DataFrame.)\n",
    "\n",
    "We can display the data as a table, too, although Jupyter notebooks aren't great for browsing through raw data. Usually, displaying a few rows is enough to give us a sense of what we're working with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But some of the columns are missing! We can fix this by adjusting a Pandas library setting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max.columns\", None)  # None means no maximum, a.k.a. everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Cleaning up columns\n",
    "\n",
    "It's pretty common that raw data files will have way more columns than you need, with obscure names as well.\n",
    "\n",
    "My favorite approach is to start by creating _new_ columns with better names. This is more flexible than renaming columns in place because it's easier to undo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rent'] = df['2019-12']  # we only care about the most recent values\n",
    "df['region'] = df['RegionName']\n",
    "df['ranking'] = df['SizeRank']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What did this do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)  # passing an integer gives us a custom number of rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we can make a copy of the DataFrame with just the columns we want:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rents = df[['region', 'rent', 'ranking']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(For the curious: This will also work without `copy()` at the end. But sometimes you'll run into errors later on. **Without** `copy()`, the new variable only contains a reference to sections of the original DataFrame -- so if you try to change any of the data values, you run into problems. **With** copy, you truly duplicate the contents.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rents.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Descriptive statistics\n",
    "\n",
    "Pandas provides a panel of pre-defined descriptive statistics that are a good place to start:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rents.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Too many decimals! We can fix this with another setting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.precision\", 1)  # number of decimal places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rents.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"descriptions\" of non-numeric columns follows a different format, and we have to ask for them separately:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rents['region'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are also built-in functions to provide individual stats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rents['rent'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use functions that are defined in other places, too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(rents['rent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.max(rents['rent'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's going on with the different kinds of syntax for calling functions?\n",
    "\n",
    "Functions that you run by appending their name to the DataFrame, like `df['colname'].max()` are part of Pandas. (Technically, these are called \"methods\" rather than functions, for reasons we don't need to go into.) \n",
    "\n",
    "Here's the full list: https://pandas.pydata.org/pandas-docs/version/0.23.4/generated/pandas.DataFrame.html\n",
    "\n",
    "With functions that come from other places, you pass the data you're evaluating into the function.\n",
    "\n",
    "Here are some other common sources for math functions: \n",
    "\n",
    "- Core Python, like `max(list)`: https://docs.python.org/3/library/functions.html\n",
    "- Core Python's math library: https://docs.python.org/3/library/math.html\n",
    "- NumPy, like `np.max(list)`: https://numpy.readthedocs.io/en/latest/reference/routines.math.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Digging into the data\n",
    "\n",
    "Which cities have the highest and lowest rents?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rents.nlargest(n=10, columns='rent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rents.nsmallest(n=10, columns='rent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we want to limit it to the 50 largest metros? This requires filtering the data.\n",
    "\n",
    "`df.loc[expression]` will filter a DataFrame to include only the specified rows and columns. For arcane reasons, the expression needs to refer to columns by their full identifier, not just their label.\n",
    "\n",
    "Generally, we use square brackets when we're **accessing a subset of data**, or defining a list. We use parentheses everywhere else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rents.loc[rents['ranking'] < 50].nlargest(n=5, columns='rent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rents.loc[rents['ranking'] < 50].nsmallest(n=5, columns='rent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which are the large metros with rents over $1,800?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rents.loc[(rents['ranking'] < 50) & (rents['rent'] > 1800)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need the extra parentheses so Python knows to evaluate each expression separately before calculating the union. (Otherwise there's a syntax error.) The symbol for \"or\" is `|`, from under the delete key.\n",
    "\n",
    "If your expressions get complicated, you can break the lines between sets of parentheses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rents.loc[(rents['region'].str.contains('CA')) & \n",
    "          (rents['rent'] > 2000)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Saving data tables to disk\n",
    "\n",
    "Often you'll want to save the results of your analysis to disk, either for record keeping or so you can look at the data using other tools. This is easy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rents.to_csv('processed_rents.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you should see it in the JupyterHub file browser."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "Are there any cities in California, Oregon, or Washington where the mean rent is below $1500?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you plot a histogram of nationwide rents, using `.plot.hist()`? \n",
    "\n",
    "You'll need to run this on a single Series, rather than on a DataFrame as in the `.plot.scatter()` example. \n",
    "\n",
    "`.plot.hist()` does not require any arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you make the histogram smoother? \n",
    "\n",
    "`.plot.hist()` takes an optional argument named `bins`, which defines how many buckets the data is divided into."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(You might want to create a new notebook for the next part, to keep things cleaner.)\n",
    "\n",
    "Make a new variable showing the percentage change in rents from 2009 to 2019.\n",
    "\n",
    "You can do this analogously to how we renamed the variables, but including a math expression on the right-hand side of the `=` assignment operator.\n",
    "\n",
    "What's the mean and range of the changes?\n",
    "\n",
    "Which cities had the largest and smallest changes?\n",
    "\n",
    "What does a histogram of the changes look like? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
